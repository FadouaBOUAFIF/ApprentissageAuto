{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FadouaBOUAFIF/ApprentissageAuto/blob/main/version_25_avril.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a13054e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "6a13054e",
        "outputId": "a81d43ab-a713-4f2a-ac6c-4ecfe64802f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Volumes/dp-datalake-dev-default/test/test/4NSigComp2010.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63dd657abb9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mextract_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Volumes/dp-datalake-dev-default/test/test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/dp-datalake-dev-default/test/test/4NSigComp2010.zip'"
          ]
        }
      ],
      "source": [
        "# Databricks notebook source\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/Volumes/dp-datalake-dev-default/test/test/4NSigComp2010.zip\"  # change to your .zip file path\n",
        "extract_dir = \"/Volumes/dp-datalake-dev-default/test/test\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Unzipped to:\", extract_dir)\n",
        "\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC\n",
        "# MAGIC %pip install torch torchvision timm\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %pip install opencv-python\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # SWIN-SIAMESE MODEL\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------------\n",
        "# 1. Dataset Preparation\n",
        "# --------------------------\n",
        "genuine_dir = \"/Volumes/dp-datalake-dev-default/test/test/genuines\"\n",
        "forged_dir = \"/Volumes/dp-datalake-dev-default/test/test/forgeries\"\n",
        "\n",
        "genuine_paths = [os.path.join(genuine_dir, f) for f in os.listdir(genuine_dir)]\n",
        "forged_paths = [os.path.join(forged_dir, f) for f in os.listdir(forged_dir)]\n",
        "\n",
        "genuine_train, genuine_test = train_test_split(genuine_paths, test_size=0.2, random_state=42)\n",
        "forged_train, forged_test = train_test_split(forged_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Data Augmentation\n",
        "# --------------------------\n",
        "class SignatureTransform:\n",
        "    def __init__(self, train=True):\n",
        "        self.train = train\n",
        "        self.base_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        edges = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n",
        "        edges = np.stack([edges] * 3, axis=-1)\n",
        "        img = np.clip(img + 0.5 * edges, 0, 255).astype(np.uint8)\n",
        "        img = self.base_transform(img)\n",
        "\n",
        "        if self.train:\n",
        "            img = transforms.RandomPerspective(distortion_scale=0.3, p=0.5)(img)\n",
        "            img = transforms.ColorJitter(brightness=0.2, contrast=0.2)(img)\n",
        "            img = transforms.RandomRotation(10)(img)\n",
        "            img = transforms.RandomResizedCrop(224, scale=(0.9, 1.1))(img)\n",
        "        else:\n",
        "            img = transforms.Resize(256)(img)\n",
        "            img = transforms.CenterCrop(224)(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "# --------------------------\n",
        "# 3. Dataset Implementation\n",
        "# --------------------------\n",
        "class SwinSiameseDataset(Dataset):\n",
        "    def __init__(self, genuine_paths, forged_paths, transform=None):\n",
        "        self.genuine_paths = genuine_paths\n",
        "        self.forged_paths = forged_paths\n",
        "        self.transform = transform\n",
        "        self.pairs = self._generate_pairs()\n",
        "\n",
        "    def _generate_pairs(self):\n",
        "        pairs = []\n",
        "        for i in range(len(self.genuine_paths)):\n",
        "            for j in range(i + 1, min(i + 10, len(self.genuine_paths))):\n",
        "                pairs.append((self.genuine_paths[i], self.genuine_paths[j], 1))\n",
        "\n",
        "        for genuine in self.genuine_paths:\n",
        "            sampled_forged = random.sample(self.forged_paths, min(5, len(self.forged_paths)))\n",
        "            for forged in sampled_forged:\n",
        "                pairs.append((genuine, forged, 0))\n",
        "\n",
        "        random.shuffle(pairs)\n",
        "        return pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1_path, img2_path, label = self.pairs[idx]\n",
        "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
        "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# --------------------------\n",
        "# 4. Model Definition\n",
        "# --------------------------\n",
        "class SwinSignatureNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = timm.create_model(\n",
        "            'swin_tiny_patch4_window7_224', pretrained=True, num_classes=0, features_only=True\n",
        "        )\n",
        "        feature_dim = self.feature_extractor.feature_info.channels()[-1]\n",
        "\n",
        "        self.local_attention = nn.Sequential(\n",
        "            nn.Conv2d(feature_dim, feature_dim, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(feature_dim * 4, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Mish(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.InstanceNorm1d(512),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self._process_single(x1)\n",
        "        f2 = self._process_single(x2)\n",
        "        diff = torch.abs(f1 - f2)\n",
        "        prod = f1 * f2\n",
        "        features = torch.cat([f1, f2, diff, prod], dim=1)\n",
        "        return self.head(features)\n",
        "\n",
        "    def _process_single(self, x):\n",
        "        features = self.feature_extractor(x)[-1]\n",
        "        features = features.permute(0, 3, 1, 2)\n",
        "        attention = self.local_attention(features)\n",
        "        features = features * attention\n",
        "        return F.adaptive_avg_pool2d(features, (1, 1)).view(features.size(0), -1)\n",
        "\n",
        "# --------------------------\n",
        "# 5. Loss Function\n",
        "# --------------------------\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# --------------------------\n",
        "# 6. Optimizer Setup\n",
        "# --------------------------\n",
        "def get_optimizer(model, loader):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=3e-4, steps_per_epoch=len(loader), epochs=50\n",
        "    )\n",
        "    return optimizer, scheduler\n",
        "\n",
        "# --------------------------\n",
        "# 7. Train & Eval\n",
        "# --------------------------\n",
        "def train_epoch(model, loader, optimizer, criterion, device, scaler):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for img1, img2, label in loader:\n",
        "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(img1, img2).squeeze()\n",
        "            loss = criterion(outputs, label)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (preds == label).sum().item()\n",
        "        total += label.size(0)\n",
        "\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    all_logits = []\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for img1, img2, label in loader:\n",
        "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "            logits = model(img1, img2).squeeze()\n",
        "            loss = criterion(logits, label)\n",
        "            total_loss += loss.item()\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).float()\n",
        "            correct += (preds == label).sum().item()\n",
        "            total += label.size(0)\n",
        "\n",
        "            all_logits.append(probs.cpu().numpy())\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(label.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    acc = correct / total\n",
        "    all_logits = np.concatenate(all_logits)\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    return avg_loss, acc, all_logits, all_preds, all_labels\n",
        "\n",
        "# --------------------------\n",
        "# 8. Distribution Check\n",
        "# --------------------------\n",
        "def check_pair_distribution(dataset):\n",
        "    pos = sum(1 for _, _, label in dataset.pairs if label == 1)\n",
        "    neg = sum(1 for _, _, label in dataset.pairs if label == 0)\n",
        "    total = len(dataset.pairs)\n",
        "    print(f\"Total Pairs: {total}\\nPositive: {pos} ({pos/total:.2%})\\nNegative: {neg} ({neg/total:.2%})\")\n",
        "\n",
        "# --------------------------\n",
        "# 9. Main Execution\n",
        "# --------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_dataset = SwinSiameseDataset(genuine_train, forged_train, transform=SignatureTransform(train=True))\n",
        "    test_dataset = SwinSiameseDataset(genuine_test, forged_test, transform=SignatureTransform(train=False))\n",
        "\n",
        "    print(\"\\n Train Dataset Distribution:\")\n",
        "    check_pair_distribution(train_dataset)\n",
        "    print(\"\\n Test Dataset Distribution:\")\n",
        "    check_pair_distribution(test_dataset)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "    model = SwinSignatureNetwork().to(device)\n",
        "    criterion = FocalLoss()\n",
        "    optimizer, scheduler = get_optimizer(model, train_loader)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(20):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
        "        test_loss, test_acc, logits, preds, labels = evaluate(model, test_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "\n",
        "        # Compute F1\n",
        "        f1 = f1_score(labels, preds)\n",
        "\n",
        "        # Compute ROC curve and AUC\n",
        "        fpr, tpr, _ = roc_curve(labels, logits)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Save best model\n",
        "        if test_acc > best_accuracy:\n",
        "            best_accuracy = test_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(f\"New best model saved at epoch {epoch+1} with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Epoch {epoch+1:02d}: \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} || \"\n",
        "              f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | \"\n",
        "              f\"F1: {f1:.4f} | AUC: {roc_auc:.4f}\")\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'ROC Curve Epoch {epoch+1}')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.savefig(f'roc_epoch_{epoch+1}.png')\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"\\nTraining complete. Best Test Accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # SIAMESE MODEL\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------------------------\n",
        "# 1. Dataset Preparation\n",
        "# --------------------------\n",
        "genuine_paths = [os.path.join(\"/Volumes/dp-datalake-dev-default/test/test/genuines\", f) for f in os.listdir(\"/Volumes/dp-datalake-dev-default/test/test/genuines\")]\n",
        "forged_paths = [os.path.join(\"/Volumes/dp-datalake-dev-default/test/test/forgeries\", f) for f in os.listdir(\"/Volumes/dp-datalake-dev-default/test/test/forgeries\")]\n",
        "\n",
        "genuine_train, genuine_test = train_test_split(genuine_paths, test_size=0.2, random_state=42)\n",
        "forged_train, forged_test = train_test_split(forged_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Lightweight Data Augmentation\n",
        "# --------------------------\n",
        "class SimpleTransform:\n",
        "    def __init__(self, train=True):\n",
        "        self.train = train\n",
        "        self.base = transforms.Compose([\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if not isinstance(img, Image.Image):\n",
        "            img = Image.fromarray(img)\n",
        "        gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
        "        edges = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n",
        "        img = np.clip(np.array(img) + 0.3 * np.stack([edges]*3, axis=-1), 0, 255)\n",
        "        img = Image.fromarray(img.astype(np.uint8))\n",
        "        img = self.base(img)\n",
        "\n",
        "        if self.train:\n",
        "            img = transforms.RandomPerspective(0.2, p=0.5)(img)\n",
        "        return img\n",
        "\n",
        "# --------------------------\n",
        "# 3. Memory-Efficient Siamese Model\n",
        "# --------------------------\n",
        "class LightSiamese(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 128x128 -> 64x64\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # 64x64 -> 32x32\n",
        "        )\n",
        "        self.feature_dim = 64 * 32 * 32\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim * 2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1) )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        return self.cnn(x).view(x.size(0), -1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        feat1 = self.forward_once(x1)\n",
        "        feat2 = self.forward_once(x2)\n",
        "        combined = torch.cat([feat1, feat2], dim=1)\n",
        "        return self.head(combined).squeeze()\n",
        "\n",
        "# --------------------------\n",
        "# 4. Training Utilities with Metrics\n",
        "# --------------------------\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img1, img2, labels in loader:\n",
        "            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
        "            outputs = model(img1, img2)\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > 0.5).float()\n",
        "\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    auc_score = roc_auc_score(all_labels, all_probs)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    # Plot ROC curve\n",
        "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'AUC={auc_score:.2f}')\n",
        "    plt.plot([0,1],[0,1],'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend()\n",
        "    plt.savefig('roc_curve.png')\n",
        "    plt.close()\n",
        "\n",
        "    return f1, auc_score, acc\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for img1, img2, labels in loader:\n",
        "        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(img1, img2)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "# --------------------------\n",
        "# 5. Dataset Class\n",
        "# --------------------------\n",
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, genuine, forged, transform=None):\n",
        "        self.img1_paths, self.img2_paths, self.labels = self._create_pairs(genuine, forged)\n",
        "        self.transform = transform or SimpleTransform()\n",
        "\n",
        "    def _create_pairs(self, genuine, forged):\n",
        "        pairs = []\n",
        "        # Genuine-genuine pairs\n",
        "        for i in range(len(genuine)-1):\n",
        "            pairs.append((genuine[i], genuine[i+1], 1))\n",
        "        # Genuine-forged pairs\n",
        "        for i in range(min(len(genuine), len(forged))):\n",
        "            pairs.append((genuine[i], forged[i], 0))\n",
        "        return list(zip(*pairs)) if pairs else ([],[],[])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1 = Image.open(self.img1_paths[idx]).convert('RGB')\n",
        "        img2 = Image.open(self.img2_paths[idx]).convert('RGB')\n",
        "        return self.transform(img1), self.transform(img2), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "# --------------------------\n",
        "# 6. Main Execution (20 epochs)\n",
        "# --------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Data\n",
        "    train_data = SiameseDataset(genuine_train, forged_train, SimpleTransform(train=True))\n",
        "    test_data = SiameseDataset(genuine_test, forged_test, SimpleTransform(train=False))\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=16)\n",
        "\n",
        "    # Model\n",
        "    model = LightSiamese().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    best_f1 = 0\n",
        "    for epoch in range(20):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        f1, auc, test_acc = evaluate(model, test_loader, device)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            torch.save(model.state_dict(), 'best_siamese.pth')\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/20: \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Test F1: {f1:.4f} | Test AUC: {auc:.4f} | Test Acc: {test_acc:.4f} | \"\n",
        "              f\"Best F1: {best_f1:.4f}\")\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC # SWIN\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_curve, auc, roc_auc_score, confusion_matrix, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    IMG_SIZE = 224\n",
        "    CHANNELS = 3\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 20\n",
        "    LR = 1e-4\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    SEED = 42\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(Config.SEED)\n",
        "random.seed(Config.SEED)\n",
        "np.random.seed(Config.SEED)\n",
        "\n",
        "# --------------------------\n",
        "# 1. Signature Dataset (Single Image)\n",
        "# --------------------------\n",
        "class SignatureDataset(Dataset):\n",
        "    def __init__(self, genuine_paths, forged_paths, transform=None):\n",
        "        self.paths = genuine_paths + forged_paths\n",
        "        self.labels = [1] * len(genuine_paths) + [0] * len(forged_paths)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# --------------------------\n",
        "# 2. Data Augmentation\n",
        "# --------------------------\n",
        "class SignatureTransform:\n",
        "    def __init__(self, train=True):\n",
        "        self.train = train\n",
        "        self.base_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "\n",
        "        # Edge enhancement\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        edges = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n",
        "        edges = np.stack([edges]*3, axis=-1)\n",
        "        img = np.clip(img + 0.3*edges, 0, 255).astype(np.uint8)\n",
        "\n",
        "        if self.train:\n",
        "            augmentations = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
        "                transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "                transforms.RandomResizedCrop(Config.IMG_SIZE, scale=(0.8, 1.0)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "            ])(img)\n",
        "        else:\n",
        "            augmentations = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize(Config.IMG_SIZE),\n",
        "                transforms.CenterCrop(Config.IMG_SIZE),\n",
        "            ])(img)\n",
        "\n",
        "        return self.base_transform(augmentations)\n",
        "\n",
        "# --------------------------\n",
        "# 3. Swin Transformer Model\n",
        "# --------------------------\n",
        "class SwinSignatureClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.swin = timm.create_model(\n",
        "            'swin_tiny_patch4_window7_224',\n",
        "            pretrained=True,\n",
        "            num_classes=1  # Let timm handle the final classification layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.swin(x).squeeze()\n",
        "\n",
        "# --------------------------\n",
        "# 4. Training Utilities\n",
        "# --------------------------\n",
        "def create_data_loaders(genuine_dir, forged_dir, test_size=0.2):\n",
        "    genuine_paths = [os.path.join(genuine_dir, f) for f in os.listdir(genuine_dir)]\n",
        "    forged_paths = [os.path.join(forged_dir, f) for f in os.listdir(forged_dir)]\n",
        "\n",
        "    # Split datasets\n",
        "    genuine_train, genuine_test = train_test_split(genuine_paths, test_size=test_size, random_state=Config.SEED)\n",
        "    forged_train, forged_test = train_test_split(forged_paths, test_size=test_size, random_state=Config.SEED)\n",
        "\n",
        "    train_dataset = SignatureDataset(\n",
        "        genuine_train, forged_train,\n",
        "        transform=SignatureTransform(train=True)\n",
        "    )\n",
        "    test_dataset = SignatureDataset(\n",
        "        genuine_test, forged_test,\n",
        "        transform=SignatureTransform(train=False)\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=Config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=Config.BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def plot_roc_curve(true_labels, pred_probs, epoch=None):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, pred_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
        "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve{\" - Epoch \"+str(epoch) if epoch else \"\"}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(f'roc_curve{\"_epoch\"+str(epoch) if epoch else \"\"}.png')\n",
        "    plt.close()\n",
        "\n",
        "# --------------------------\n",
        "# 5. Training Loop\n",
        "# --------------------------\n",
        "def train():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Initialize\n",
        "    train_loader, test_loader = create_data_loaders(\n",
        "        genuine_dir=\"/Volumes/dp-datalake-dev-default/test/test/genuines\",\n",
        "        forged_dir=\"/Volumes/dp-datalake-dev-default/test/test/forgeries\"\n",
        "    )\n",
        "\n",
        "    model = SwinSignatureClassifier().to(Config.DEVICE)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    best_acc = 0\n",
        "    best_metrics = {'f1': 0, 'auc': 0}\n",
        "\n",
        "    for epoch in range(Config.EPOCHS):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0, 0\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.EPOCHS} [Train]\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            train_correct += (preds == labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': train_loss/len(pbar),\n",
        "                'acc': train_correct/((pbar.n+1)*Config.BATCH_SIZE)\n",
        "            })\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct = 0, 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{Config.EPOCHS} [Val]\"):\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "\n",
        "                outputs = model(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).float()\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "        val_loss /= len(test_loader)\n",
        "        val_acc = val_correct / len(test_loader.dataset)\n",
        "        val_f1 = f1_score(all_labels, all_preds)\n",
        "        val_auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_metrics = {'f1': val_f1, 'auc': val_auc}\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "                'val_f1': val_f1,\n",
        "                'val_auc': val_auc,\n",
        "            }, \"best_swin_classifier.pth\")\n",
        "\n",
        "            # Plot ROC curve for best model\n",
        "            plot_roc_curve(all_labels, all_probs, epoch+1)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}: \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | \"\n",
        "              f\"F1: {val_f1:.4f} | AUC: {val_auc:.4f} | \"\n",
        "              f\"Best Acc: {best_acc:.4f}\")\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nTraining complete. Best Val Accuracy: {best_acc:.4f}\")\n",
        "    print(f\"Best F1 Score: {best_metrics['f1']:.4f}\")\n",
        "    print(f\"Best ROC AUC: {best_metrics['auc']:.4f}\")\n",
        "\n",
        "    # Load best model and evaluate on test set\n",
        "    best_model = SwinSignatureClassifier().to(Config.DEVICE)\n",
        "    checkpoint = torch.load(\"best_swin_classifier.pth\", weights_only=False)\n",
        "    best_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Final evaluation function\n",
        "    best_model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Final Evaluation\"):\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            outputs = best_model(images)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > 0.5).float()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    # Calculate final metrics\n",
        "    final_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    final_f1 = f1_score(all_labels, all_preds)\n",
        "    final_auc = roc_auc_score(all_labels, all_probs)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(\"\\nFinal Test Set Performance:\")\n",
        "    print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {final_f1:.4f}\")\n",
        "    print(f\"ROC AUC: {final_auc:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Plot final ROC curve\n",
        "    plot_roc_curve(all_labels, all_probs, \"final\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}